{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpgMM4icXH-F"
      },
      "source": [
        "## Setup environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFgvGvNxXH-G"
      },
      "outputs": [],
      "source": [
        "!python -c \"import monai\" || pip install -q \"monai-weekly[pillow, tqdm]\"\n",
        "!python -c \"import matplotlib\" || pip install -q matplotlib\n",
        "!pip install scipy\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtdIFHvTXH-G"
      },
      "source": [
        "## Setup imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84w9PPZhXH-G",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Copyright 2020 MONAI Consortium\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import tempfile\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from monai.apps import download_and_extract\n",
        "from monai.config import print_config\n",
        "from monai.data import decollate_batch, DataLoader\n",
        "from monai.metrics import ROCAUCMetric\n",
        "from monai.networks.nets import DenseNet121\n",
        "from monai.networks.nets import ResNet\n",
        "from monai.networks.nets import EfficientNetBN\n",
        "from monai.transforms import (\n",
        "    Activations,\n",
        "    EnsureChannelFirst,\n",
        "    AsDiscrete,\n",
        "    Compose,\n",
        "    LoadImage,\n",
        "    RandFlip,\n",
        "    RandRotate,\n",
        "    RandZoom,\n",
        "    ScaleIntensity,\n",
        ")\n",
        "from monai.utils import set_determinism\n",
        "\n",
        "print_config()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2x-Lem1SXH-H"
      },
      "source": [
        "## Setup data directory\n",
        "\n",
        "You can specify a directory with the `MONAI_DATA_DIRECTORY` environment variable.  \n",
        "This allows you to save results and reuse downloads.  \n",
        "If not specified a temporary directory will be used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bkNS-pM7XH-H",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Especificar un directorio con la variable de entorno MONAI_DATA_DIRECTORY,\n",
        "# permitiendo esto guardar los resultados y reutilizar las descargas.\n",
        "# Si no se especifica, se utilizará un directorio temporal.\n",
        "\n",
        "directory = os.environ.get(\"MONAI_DATA_DIRECTORY\")\n",
        "root_dir = tempfile.mkdtemp() if directory is None else directory\n",
        "print(root_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NnhDBzSPXH-I",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Este código gestiona la descarga y extracción del conjutno de datos (MedNIST.tar.gz) desde una URL específica.\n",
        "# Se verifica la integridad del archivo mediante su hash MD5 antes de la descarga.\n",
        "# El recurso se almacena en un archivo comprimido en el directorio raíz y se extrae en un directorio de datos.\n",
        "# La descarga y extracción solo se realizan si el directorio de datos aún no existe.\n",
        "resource = \"https://github.com/Project-MONAI/MONAI-extra-test-data/releases/download/0.8.1/MedNIST.tar.gz\"\n",
        "md5 = \"0bc7306e7427e00ad1c5526a6677552d\"\n",
        "\n",
        "compressed_file = os.path.join(root_dir, \"MedNIST.tar.gz\")\n",
        "data_dir = os.path.join(root_dir, \"MedNIST\")\n",
        "if not os.path.exists(data_dir):\n",
        "    download_and_extract(resource, compressed_file, root_dir, md5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xCxgejZXH-J"
      },
      "source": [
        "## Set deterministic training for reproducibility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZVqe06kXH-J"
      },
      "outputs": [],
      "source": [
        "# Establecer el determinismo en el código, utilizando una semilla (seed) específica.\n",
        "# Esto garantiza que las operaciones aleatorias generadas en el código sean reproducibles, siempre y cuando\n",
        "# se utilice la misma semilla. Útil para la reproducibilidad de resultados en tareas como entrenamiento de modelos.\n",
        "\n",
        "set_determinism(seed=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVkbhSc1XH-J"
      },
      "source": [
        "## Read image filenames from the dataset folders\n",
        "\n",
        "First of all, check the dataset files and show some statistics.  \n",
        "There are 6 folders in the dataset: Hand, AbdomenCT, CXR, ChestCT, BreastMRI, HeadCT,  \n",
        "which should be used as the labels to train our classification model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GBAnU15_XH-J",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Obtener la lista ordenada de nombres de clases a partir de los subdirectorios en el directorio de datos\n",
        "class_names = sorted(x for x in os.listdir(data_dir)\n",
        "                     if os.path.isdir(os.path.join(data_dir, x)))\n",
        "\n",
        "# Calcular el número total de clases\n",
        "num_class = len(class_names)\n",
        "\n",
        "# Obtener la lista de rutas de archivos de imagen para cada clase\n",
        "image_files = [\n",
        "    [\n",
        "        os.path.join(data_dir, class_names[i], x)\n",
        "        for x in os.listdir(os.path.join(data_dir, class_names[i]))\n",
        "    ]\n",
        "    for i in range(num_class)\n",
        "]\n",
        "\n",
        "#Calcular el número de imágenes en cada clase\n",
        "num_each = [len(image_files[i]) for i in range(num_class)]\n",
        "\n",
        "# Crear una lista plana de rutas de archivos de imagen y una lista de etiquetas correspondientes\n",
        "image_files_list = []\n",
        "image_class = []\n",
        "for i in range(num_class):\n",
        "    image_files_list.extend(image_files[i])\n",
        "    image_class.extend([i] * num_each[i])\n",
        "\n",
        "# Calcular el número total de imágenes\n",
        "num_total = len(image_class)\n",
        "\n",
        "# Obtener las dimensiones de la primera imagen\n",
        "image_width, image_height = PIL.Image.open(image_files_list[0]).size\n",
        "\n",
        "print(PIL.Image.open(image_files_list[0]))\n",
        "print(f\"Total image count: {num_total}\")\n",
        "print(f\"Image dimensions: {image_width} x {image_height}\")\n",
        "print(f\"Label names: {class_names}\")\n",
        "print(f\"Label counts: {num_each}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0C3cZculXH-J"
      },
      "source": [
        "## Randomly pick images from the dataset to visualize and check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ec3jIC9DXH-J"
      },
      "outputs": [],
      "source": [
        "# Este código carga y muestra 10 imágenes en una cuadrícula de 2 filas y 5 columnas.\n",
        "\n",
        "plt.subplots(2, 5, figsize=(8, 8))\n",
        "for i, k in enumerate(np.random.randint(num_total, size=10)):\n",
        "    im = PIL.Image.open(image_files_list[k])\n",
        "    arr = np.array(im)\n",
        "    plt.subplot(2, 5, i + 1)\n",
        "    plt.xlabel(class_names[image_class[k]])\n",
        "    plt.imshow(arr, vmin=0, vmax=255)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSOKl90xXH-K"
      },
      "source": [
        "## Prepare training, validation and test data lists\n",
        "\n",
        "Randomly select 10% of the dataset as validation and 10% as test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H76Upye_XH-K",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Dividir los índices de las imágenes en conjuntos de entrenamiento, validación y test\n",
        "# utilizando porcentajes porcentajes para cada uno de los conjuntos\n",
        "val_frac = 0.1\n",
        "test_frac = 0.1\n",
        "length = len(image_files_list)\n",
        "indices = np.arange(length)\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "# Calcular los índices para cada conjunto según los porcertajes especificados\n",
        "test_split = int(test_frac * length)\n",
        "val_split = int(val_frac * length) + test_split\n",
        "test_indices = indices[:test_split]\n",
        "val_indices = indices[test_split:val_split]\n",
        "train_indices = indices[val_split:]\n",
        "\n",
        "# Crear listas de rutas de archivos y etiquetas para cada conjunto\n",
        "train_x = [image_files_list[i] for i in train_indices]\n",
        "train_y = [image_class[i] for i in train_indices]\n",
        "val_x = [image_files_list[i] for i in val_indices]\n",
        "val_y = [image_class[i] for i in val_indices]\n",
        "test_x = [image_files_list[i] for i in test_indices]\n",
        "test_y = [image_class[i] for i in test_indices]\n",
        "\n",
        "print(\n",
        "    f\"Training count: {len(train_x)}, Validation count: \"\n",
        "    f\"{len(val_x)}, Test count: {len(test_x)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQzjC5dyXH-K"
      },
      "source": [
        "## Define MONAI transforms, Dataset and Dataloader to pre-process data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "csLFxT8hXH-K"
      },
      "outputs": [],
      "source": [
        "# Definir transformaciones de datos para los conjuntos de entrenamiento, validación y predicciones\n",
        "\n",
        "# Transformaciones para el conjunto de entrenamiento\n",
        "train_transforms = Compose(\n",
        "    [\n",
        "        LoadImage(image_only=True), # Cargar la imagen\n",
        "        EnsureChannelFirst(), # Asegurar que los canales estén en la primera dimensión\n",
        "        ScaleIntensity(), # Escalar la intensidad de los píxeles\n",
        "        RandRotate(range_x=np.pi / 12, prob=0.5, keep_size=True), # Rotación aleatoria\n",
        "        RandFlip(spatial_axis=0, prob=0.5), # Volteo aleatorio en el eje espacial 0 (horizontal)\n",
        "        RandZoom(min_zoom=0.9, max_zoom=1.1, prob=0.5), # Zoom aleatorio\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Transformaciones para el conjunto de validación\n",
        "val_transforms = Compose(\n",
        "    [LoadImage(image_only=True), EnsureChannelFirst(), ScaleIntensity()])\n",
        "\n",
        "# Transformaciones para las predicciones\n",
        "y_pred_trans = Compose([Activations(softmax=True)]) # Aplicar funciones de activación softmax\n",
        "\n",
        "# Transformaciones para las etiquetas\n",
        "y_trans = Compose([AsDiscrete(to_onehot=num_class)]) # Convertir a representación one-hot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mLk0i-43XH-K"
      },
      "outputs": [],
      "source": [
        "# Definir la clase MedNISTDataset que hereda de torch.utils.data.Dataset.\n",
        "# Esta clase se utiliza para crear los conjuntos de datos (entrenamiento, validación y test),\n",
        "# que contienen rutas de archivos de imágenes y etiquetas correspondientes, así como\n",
        "# las transformaciones que se aplicarán durante la evaluación.\n",
        "\n",
        "class MedNISTDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, image_files, labels, transforms):\n",
        "        self.image_files = image_files\n",
        "        self.labels = labels\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.transforms(self.image_files[index]), self.labels[index]\n",
        "\n",
        "workers = 2\n",
        "\n",
        "# Crear un conjunto de datos de entrenamiento utilizando la clase MedNISTDataset\n",
        "# y configurar un cargador de datos utilizando DataLoader de PyTorch.\n",
        "train_ds = MedNISTDataset(train_x, train_y, train_transforms)\n",
        "train_loader = DataLoader(\n",
        "    train_ds, batch_size=100, shuffle=True, num_workers=workers)\n",
        "\n",
        "# Crear un conjunto de datos de validación utilizando la clase MedNISTDataset\n",
        "# y configurar un cargador de datos utilizando DataLoader de PyTorch.\n",
        "val_ds = MedNISTDataset(val_x, val_y, val_transforms)\n",
        "val_loader = DataLoader(\n",
        "    val_ds, batch_size=100, num_workers=workers)\n",
        "\n",
        "# Crear un conjunto de datos de test utilizando la clase MedNISTDataset\n",
        "# y configurar un cargador de datos utilizando DataLoader de PyTorch.\n",
        "test_ds = MedNISTDataset(test_x, test_y, val_transforms)\n",
        "test_loader = DataLoader(\n",
        "    test_ds, batch_size=100, num_workers=workers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G2-E9x5fbQFo"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "from scipy.spatial.distance import cdist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1fny86AbYsq"
      },
      "outputs": [],
      "source": [
        "class GCNN_ECNN(nn.Module):\n",
        "    def __init__(self, img_size=64, pred_edge=False):\n",
        "        super(GCNN_ECNN, self).__init__()\n",
        "\n",
        "        # Establecer el indicador de predicción de bordes\n",
        "        self.pred_edge = pred_edge\n",
        "        # Calcular el tamaño de la entrada para la capa completamente conectada\n",
        "        N = img_size ** 2\n",
        "\n",
        "        # Capa completamente conectada que toma la entrada de tamaño N y produce una salida de 6 clases\n",
        "        self.fc = nn.Linear(N, 6, bias=True)\n",
        "\n",
        "        # Verificar si se debe realizar la predicción de bordes\n",
        "        if pred_edge:\n",
        "            # Preparar coordenadas normalizadas para la predicción de bordes\n",
        "            col, row = np.meshgrid(np.arange(img_size), np.arange(img_size))\n",
        "            coord = np.stack((col, row), axis=2).reshape(-1, 2)\n",
        "            coord = (coord - np.mean(coord, axis=0)) / (np.std(coord, axis=0) + 1e-5)\n",
        "            coord = torch.from_numpy(coord).float()  # 784,2\n",
        "            # Expandir las coordenadas para su uso en la red neuronal\n",
        "            coord = torch.cat((coord.unsqueeze(0).repeat(N, 1,  1),\n",
        "                                    coord.unsqueeze(1).repeat(1, N, 1)), dim=2)\n",
        "            #coord = torch.abs(coord[:, :, [0, 1]] - coord[:, :, [2, 3]]) # this should have worked\n",
        "            # Definir la red neuronal para la predicción de bordes\n",
        "            self.pred_edge_fc = nn.Sequential(nn.Linear(4, 32), # Esto puede ser un hiperparámetro\n",
        "                                              nn.ReLU(),\n",
        "                                              nn.Linear(32, 64),\n",
        "                                              nn.ReLU(),\n",
        "                                              nn.Linear(64, 1),\n",
        "                                              nn.Tanh())\n",
        "            # Registrar las coordenadas como un tensor constante\n",
        "            self.register_buffer('coord', coord)\n",
        "\n",
        "        # Si no se realiza predicción de bordes\n",
        "        else:\n",
        "            # Precomputar y registrar la matriz de adyacencia para la capa GCN\n",
        "            A = self.precompute_adjacency_images(img_size)\n",
        "            self.register_buffer('A', A)\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def precompute_adjacency_images(img_size):\n",
        "\n",
        "        # Crear malla de coordenadas (col, row) para la imagen de tamaño img_size\n",
        "        col, row = np.meshgrid(np.arange(img_size), np.arange(img_size))\n",
        "        # Apilar las coordenadas (col, row) y normalizarlas\n",
        "        coord = np.stack((col, row), axis=2).reshape(-1, 2) / img_size\n",
        "        # Calcular la matriz de distancias euclidianas entre las coordenadas\n",
        "        dist = cdist(coord, coord)\n",
        "        # Parámetro de suavizado para la función de densidad gaussiana\n",
        "        sigma = 0.05 * np.pi\n",
        "\n",
        "        # Calcular la matriz de adyacencia usando una función de densidad gaussiana\n",
        "        A = np.exp(- dist / sigma ** 2)\n",
        "        print('WARNING: try squaring the dist to make it a Gaussian')\n",
        "\n",
        "        # Filtrar los elementos pequeños de la matriz de adyacencia y convertirla a tensor de PyTorch\n",
        "        A[A < 0.01] = 0\n",
        "        A = torch.from_numpy(A).float()\n",
        "\n",
        "        # Normalización según (Kipf & Welling, ICLR 2017)\n",
        "        D = A.sum(1)  # Grados de los nodos (N,)\n",
        "        D_hat = (D + 1e-5) ** (-0.5)\n",
        "        A_hat = D_hat.view(-1, 1) * A * D_hat.view(1, -1)  # N,N\n",
        "\n",
        "        # Truco adicional encontrado útil\n",
        "        A_hat[A_hat > 0.0001] = A_hat[A_hat > 0.0001] - 0.2\n",
        "\n",
        "        # print(A_hat[:10, :10])\n",
        "        return A_hat\n",
        "\n",
        "    def forward(self, x):\n",
        "        B = x.size(0)\n",
        "\n",
        "        # Actualizar la matriz de adyacencia si se está prediciendo los bordes\n",
        "        if self.pred_edge:\n",
        "            self.A = self.pred_edge_fc(self.coord).squeeze()\n",
        "\n",
        "        # Calcular características promedio de los vecinos utilizando la matriz de adyacencia\n",
        "        avg_neighbor_features = (torch.bmm(self.A.unsqueeze(0).expand(B, -1, -1),\n",
        "                                 x.view(B, -1, 1)).view(B, -1))\n",
        "\n",
        "        # Pasar las características promedio a la siguiente capa\n",
        "        return self.fc(avg_neighbor_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ZRSsA_6btz9"
      },
      "outputs": [],
      "source": [
        "# Crear una instancia del modelo GCNN_ECNN con la opción de predicción de bordes habilitada\n",
        "model = GCNN_ECNN(pred_edge=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75CQLzKaKOhb"
      },
      "outputs": [],
      "source": [
        "# Imprimir la cantidad total de parámetros en el modelo\n",
        "print(sum(p.numel() for p in model.parameters()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trgMBmQiXH-K"
      },
      "source": [
        "## Define network and optimizer\n",
        "\n",
        "1. Set learning rate for how much the model is updated per batch.\n",
        "1. Set total epoch number, as we have shuffle and random transforms, so the training data of every epoch is different.  \n",
        "And as this is just a get start tutorial, let's just train 4 epochs.  \n",
        "If train 10 epochs, the model can achieve 100% accuracy on test dataset.\n",
        "1. Use DenseNet from MONAI and move to GPU devide, this DenseNet can support both 2D and 3D classification tasks.\n",
        "1. Use Adam optimizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FIPJZj1YXH-K"
      },
      "outputs": [],
      "source": [
        "# Determina el dispositivo de ejecución\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Define como función de pérdida la entropía cruzada\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "# Crea un optimizador Adam para ajustar los parámetros del modelo\n",
        "# con una tasa de aprendizaje de 1e-5\n",
        "optimizer = torch.optim.Adam(model.parameters(), 1e-5)\n",
        "# Número máximo de épocas para el entrenamiento\n",
        "max_epochs = 50\n",
        "# Intervalo para la validación (cada cuántas épocas se realiza)\n",
        "val_interval = 1\n",
        "# Crea una métrica de área bajo la curva ROC para evaluar el rendimiento\n",
        "auc_metric = ROCAUCMetric()\n",
        "# Mueve el modelo a la GPU (si está disponible)\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obR1uqXDbwd1"
      },
      "outputs": [],
      "source": [
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LOruqnRXH-K"
      },
      "source": [
        "## Model training\n",
        "\n",
        "Execute a typical PyTorch training that run epoch loop and step loop, and do validation after every epoch.  \n",
        "Will save the model weights to file if got best validation accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I-I3nWziXH-K",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Variables para el seguimiento de la mejor métrica\n",
        "best_metric = -1\n",
        "best_metric_epoch = -1\n",
        "# Listas para almacenar los valores de pérdida y métrica en cada época\n",
        "epoch_loss_values = []\n",
        "metric_values = []\n",
        "\n",
        "# Bucle de entrenamiento\n",
        "for epoch in range(max_epochs):\n",
        "    print(\"-\" * 10)\n",
        "    print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
        "\n",
        "    # Configura el modelo en modo de entrenamiento\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    step = 0\n",
        "    for_time = []\n",
        "    back_time = []\n",
        "\n",
        "    # Itera sobre lotes de datos de entrenamiento\n",
        "    for batch_data in train_loader:\n",
        "        # print(batch_data[0].shape)\n",
        "        step += 1\n",
        "        # Mueve los datos de entrada a la GPU o CPU\n",
        "        inputs, labels = batch_data[0].to(device), batch_data[1].to(device)\n",
        "        # Inicializa los gradientes a cero\n",
        "        optimizer.zero_grad()\n",
        "        # Realiza la propagación hacia adelante (forward)\n",
        "        a = time.time()\n",
        "        outputs = model(inputs)\n",
        "        # Calcula la pérdida\n",
        "        loss = loss_function(outputs, labels)\n",
        "        b = time.time()\n",
        "        # Realiza la retropropagación y actualiza los pesos del modelo\n",
        "        loss.backward()\n",
        "        c = time.time()\n",
        "        optimizer.step()\n",
        "        d = time.time()\n",
        "\n",
        "        # Registro de los tiempos de ejecución\n",
        "        for_time.append(b-a)\n",
        "        #print(\"forward\",sum(for_time)/len(for_time))\n",
        "        epoch_loss += loss.item()\n",
        "        back_time.append(c-b)\n",
        "        # print(\"backward\",sum(back_time)/len(back_time))\n",
        "\n",
        "        print(\n",
        "            f\"{step}/{len(train_ds) // train_loader.batch_size}, \"\n",
        "            f\"train_loss: {loss.item():.4f}\")\n",
        "        epoch_len = len(train_ds) // train_loader.batch_size\n",
        "\n",
        "    # Cálculo de la pérdida promedio\n",
        "    epoch_loss /= step\n",
        "    epoch_loss_values.append(epoch_loss)\n",
        "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
        "\n",
        "    # Validación cada cierto número de épocas\n",
        "    if (epoch + 1) % val_interval == 0:\n",
        "        model.eval()\n",
        "        # Validación sobre el conjunto de validación\n",
        "        with torch.no_grad():\n",
        "            y_pred = torch.tensor([], dtype=torch.float32, device=device)\n",
        "            y = torch.tensor([], dtype=torch.long, device=device)\n",
        "            for val_data in val_loader:\n",
        "                val_images, val_labels = (\n",
        "                    val_data[0].to(device),\n",
        "                    val_data[1].to(device),\n",
        "                )\n",
        "                y_pred = torch.cat([y_pred, model(val_images)], dim=0)\n",
        "                y = torch.cat([y, val_labels], dim=0)\n",
        "\n",
        "            # Evalúa la métrica AUC-ROC en el conjunto de validación\n",
        "            y_onehot = [y_trans(i) for i in decollate_batch(y, detach=False)]\n",
        "            y_pred_act = [y_pred_trans(i) for i in decollate_batch(y_pred)]\n",
        "            auc_metric(y_pred_act, y_onehot)\n",
        "            result = auc_metric.aggregate()\n",
        "            auc_metric.reset()\n",
        "            del y_pred_act, y_onehot\n",
        "            metric_values.append(result)\n",
        "\n",
        "            # Calcula y almacena la precisión en el conjunto de validación\n",
        "            acc_value = torch.eq(y_pred.argmax(dim=1), y)\n",
        "            acc_metric = acc_value.sum().item() / len(acc_value)\n",
        "            # Actualiza el modelo si se obtiene una métrica mejor\n",
        "            if result > best_metric:\n",
        "                best_metric = result\n",
        "                best_metric_epoch = epoch + 1\n",
        "                torch.save(model.state_dict(), os.path.join(\n",
        "                    root_dir, \"best_metric_model.pth\"))\n",
        "                print(\"saved new best metric model\")\n",
        "            # Información sobre la métrica actual y la mejor métrica alcanzada\n",
        "            print(\n",
        "                f\"current epoch: {epoch + 1} current AUC: {result:.4f}\"\n",
        "                f\" current accuracy: {acc_metric:.4f}\"\n",
        "                f\" best AUC: {best_metric:.4f}\"\n",
        "                f\" at epoch: {best_metric_epoch}\"\n",
        "            )\n",
        "\n",
        "# Mensaje indicando que el entrenamiento ha sido completado\n",
        "print(\n",
        "    f\"train completed, best_metric: {best_metric:.4f} \"\n",
        "    f\"at epoch: {best_metric_epoch}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mv_7vY2HXH-L"
      },
      "source": [
        "## Plot the loss and metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kz1u6zI4XH-L"
      },
      "outputs": [],
      "source": [
        "# Configuración de la figura\n",
        "plt.figure(\"train\", (12, 6))\n",
        "# Pérdida promedio por época\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"Epoch Average Loss\")\n",
        "x = [i + 1 for i in range(len(epoch_loss_values))]\n",
        "y = epoch_loss_values\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.plot(x, y)\n",
        "# Subtrama derecha: Métrica AUC en el conjunto de validación\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(\"Val AUC\")\n",
        "x = [val_interval * (i + 1) for i in range(len(metric_values))]\n",
        "y = metric_values\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.plot(x, y)\n",
        "# Muestra la figura\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRv5cZHzXH-L"
      },
      "source": [
        "## Evaluate the model on test dataset\n",
        "\n",
        "After training and validation, we already got the best model on validation test.  \n",
        "We need to evaluate the model on test dataset to check whether it's robust and not over-fitting.  \n",
        "We'll use these predictions to generate a classification report."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MWGnWW5fXH-L"
      },
      "outputs": [],
      "source": [
        "# Carga los pesos del modelo con la mejor métrica\n",
        "model.load_state_dict(torch.load(\n",
        "    os.path.join(root_dir, \"best_metric_model.pth\")))\n",
        "\n",
        "# Entrar en modo evaluación\n",
        "model.eval()\n",
        "# Listas para almacenar las etiquetas verdaderas y las predicciones del modelo\n",
        "y_true = []\n",
        "y_pred = []\n",
        "# Realiza la evaluación en el conjunto de prueba\n",
        "with torch.no_grad():\n",
        "    for test_data in test_loader:\n",
        "        test_images, test_labels = (\n",
        "            test_data[0].to(device),\n",
        "            test_data[1].to(device),\n",
        "        )\n",
        "        # Obtención las predicciones del modelo\n",
        "        pred = model(test_images).argmax(dim=1)\n",
        "        # Almacena las etiquetas verdaderas y las predicciones\n",
        "        for i in range(len(pred)):\n",
        "            y_true.append(test_labels[i].item())\n",
        "            y_pred.append(pred[i].item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42gij0mJXH-L",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Informe de clasificación\n",
        "print(classification_report(\n",
        "    y_true, y_pred, target_names=class_names, digits=4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIGetcFpXohH"
      },
      "source": [
        "## Uncertainty"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cdH5wg3iX4mv"
      },
      "outputs": [],
      "source": [
        "length = len(image_files_list)\n",
        "indices = np.arange(length)\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "split = []\n",
        "split_prediction = []\n",
        "last_split = 0\n",
        "# Asignación de los índices a cada subconjunto\n",
        "for k in range(1,11):\n",
        "    new_split = int(0.1 * k * length)\n",
        "    new_split_indices = indices[last_split:new_split]\n",
        "    split.append([image_files_list[i] for i in new_split_indices])\n",
        "    split_prediction.append([image_class[i] for i in new_split_indices])\n",
        "    last_split = new_split\n",
        "\n",
        "\n",
        "auc = 0\n",
        "metric_values = []\n",
        "workers = 2\n",
        "\n",
        "# Iteración sobre cada uno de los subconjuntos\n",
        "for i in range(10):\n",
        "    metric_values.append([])\n",
        "\n",
        "    # Obtención de los valores de los índices\n",
        "    resultado_x = [elemento for indice, elemento in enumerate(split) if indice != i]\n",
        "    resultado_y = [elemento for indice, elemento in enumerate(split_prediction) if indice != i]\n",
        "    # Combina todas las listas en una sola\n",
        "    split_train = [elemento for sublista in resultado_x for elemento in sublista]\n",
        "    split_prediction_train = [elemento for sublista in resultado_y for elemento in sublista]\n",
        "\n",
        "    # Creación de conjunto de entrenamiento y validación\n",
        "    train_ds = MedNISTDataset(split_train, split_prediction_train, train_transforms)\n",
        "    train_loader = DataLoader(\n",
        "        train_ds, batch_size=100, shuffle=True, num_workers=workers)\n",
        "\n",
        "    test_ds = MedNISTDataset(split[i], split_prediction[i], val_transforms)\n",
        "    test_loader = DataLoader(\n",
        "        test_ds, batch_size=100, num_workers=workers)\n",
        "\n",
        "\n",
        "    # Model\n",
        "    model = GCNN_ECNN(pred_edge=True)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    loss_function = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), 1e-5)\n",
        "    max_epochs = 4\n",
        "    auc_metric = ROCAUCMetric()\n",
        "    model.to(device)\n",
        "\n",
        "    epoch_loss_values = []\n",
        "    # Bucle de entrenamiento\n",
        "    for epoch in range(max_epochs):\n",
        "        print(\"-\" * 10)\n",
        "        print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
        "\n",
        "        # Configura el modelo en modo de entrenamiento\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        step = 0\n",
        "        for_time = []\n",
        "        back_time = []\n",
        "\n",
        "        # Itera sobre lotes de datos de entrenamiento\n",
        "        for batch_data in train_loader:\n",
        "            step += 1\n",
        "            # Mueve los datos de entrada a la GPU o CPU\n",
        "            inputs, labels = batch_data[0].to(device), batch_data[1].to(device)\n",
        "            # Inicializa los gradientes a cero\n",
        "            optimizer.zero_grad()\n",
        "            # Realiza la propagación hacia adelante (forward)\n",
        "            a = time.time()\n",
        "            outputs = model(inputs)\n",
        "            # Calcula la pérdida\n",
        "            loss = loss_function(outputs, labels)\n",
        "            b = time.time()\n",
        "            # Realiza la retropropagación y actualiza los pesos del modelo\n",
        "            loss.backward()\n",
        "            c = time.time()\n",
        "            optimizer.step()\n",
        "            d = time.time()\n",
        "\n",
        "            # Registro de los tiempos de ejecución\n",
        "            for_time.append(b-a)\n",
        "            epoch_loss += loss.item()\n",
        "            back_time.append(c-b)\n",
        "            print(\n",
        "                f\"{step}/{len(train_ds) // train_loader.batch_size}, \"\n",
        "                f\"train_loss: {loss.item():.4f}\")\n",
        "            epoch_len = len(train_ds) // train_loader.batch_size\n",
        "        epoch_loss /= step\n",
        "        epoch_loss_values.append(epoch_loss)\n",
        "        print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
        "\n",
        "        # Validación\n",
        "        model.eval()\n",
        "        y_true = []\n",
        "        y_pred = []\n",
        "        with torch.no_grad():\n",
        "            y_pred = torch.tensor([], dtype=torch.float32, device=device)\n",
        "            y = torch.tensor([], dtype=torch.long, device=device)\n",
        "            for test_data in test_loader:\n",
        "                val_images, val_labels = (\n",
        "                    test_data[0].to(device),\n",
        "                    test_data[1].to(device),\n",
        "                )\n",
        "                y_pred = torch.cat([y_pred, model(val_images)], dim=0)\n",
        "                y = torch.cat([y, val_labels], dim=0)\n",
        "\n",
        "            # Evalúa la métrica AUC-ROC en el conjunto de validación\n",
        "            y_onehot = [y_trans(i) for i in decollate_batch(y, detach=False)]\n",
        "            y_pred_act = [y_pred_trans(i) for i in decollate_batch(y_pred)]\n",
        "            auc_metric(y_pred_act, y_onehot)\n",
        "            metric_values[i].append(auc_metric.aggregate())\n",
        "            auc_metric.reset()\n",
        "            del y_pred_act, y_onehot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jh6euAVsYhI2"
      },
      "outputs": [],
      "source": [
        "import statistics\n",
        "import math\n",
        "import numpy as np\n",
        "import scipy.stats as st\n",
        "\n",
        "# Resultados obtenidos\n",
        "print(\"Todos los AUC: \", metric_values)\n",
        "metric_transpose = np.array(metric_values).transpose()\n",
        "for i in range(len(metric_transpose)):\n",
        "    gfg_data = metric_transpose[i]\n",
        "    mean = np.mean(gfg_data)\n",
        "    dev = statistics.stdev(gfg_data)\n",
        "    sem = dev/math.sqrt(10)\n",
        "    conf = st.t.interval(confidence=0.95, df=len(gfg_data)-1, loc=np.mean(gfg_data), scale=sem)\n",
        "    conf = (round(conf[0], 3), round(conf[1], 3))\n",
        "    print(\"Época \", i+1, \":\")\n",
        "    print(\"----------\")\n",
        "    print(\"Media: \", round(mean,  3))\n",
        "    print(\"Desviación estándar: \", round(dev, 3))\n",
        "    print(\"SEM: \", round(sem, 3))\n",
        "    print(\"Intervalo de confianza: \", conf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyjO19N2XH-L"
      },
      "source": [
        "## Cleanup data directory\n",
        "\n",
        "Remove directory if a temporary was used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XOtFaqPsXH-L"
      },
      "outputs": [],
      "source": [
        "if directory is None:\n",
        "    shutil.rmtree(root_dir)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
